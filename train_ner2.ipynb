{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1a76088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from seqeval.scheme import IOB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e8b6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kosong bahasa Indonesia berhasil dibuat.\n"
     ]
    }
   ],
   "source": [
    "# 1. Membuat model kosong dengan bahasa Indonesia\n",
    "nlp = spacy.blank(\"id\")\n",
    "print(\"Model kosong bahasa Indonesia berhasil dibuat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce272ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Menambahkan pipeline NER secara manual\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7a4cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load data training dari file JSON (akses key 'annotations')\n",
    "with open(\"annotations.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_json = json.load(f)\n",
    "    ALL_DATA = data_json[\"annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7c76481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data training: 308, Data validasi: 133\n"
     ]
    }
   ],
   "source": [
    "# Bagi data menjadi training dan validation (70% - 30%)\n",
    "TRAIN_DATA, VALID_DATA = train_test_split(ALL_DATA, test_size=0.3, random_state=42)\n",
    "print(f\"Data training: {len(TRAIN_DATA)}, Data validasi: {len(VALID_DATA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14e31721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label yang ditambahkan: ('APP', 'DESC')\n"
     ]
    }
   ],
   "source": [
    "# 4. Tambahkan label entitas\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "print(f\"Label yang ditambahkan: {ner.labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05f38885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pelatihan dimulai...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "optimizer = nlp.begin_training()\n",
    "best_f1_tagging = 0.0\n",
    "print(\"Pelatihan dimulai...\\n\")\n",
    "\n",
    "# Pendekatan 1: Span Matching\n",
    "def evaluate_span(nlp, data):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for text, annotations in data:\n",
    "        doc = nlp(text)\n",
    "        gold = set([(start, end, label) for start, end, label in annotations.get(\"entities\")])\n",
    "        pred = set([(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
    "        tp += len(gold & pred)\n",
    "        fp += len(pred - gold)\n",
    "        fn += len(gold - pred)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65eb913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pendekatan 2: BIO Tagging dengan Seqeval\n",
    "def evaluate_bio(nlp, data):\n",
    "    true_entities_list = []\n",
    "    pred_entities_list = []\n",
    "\n",
    "    for text, annotations in data:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Prediksi dari model\n",
    "        pred_tags = []\n",
    "        for token in doc:\n",
    "            if token.ent_type_:\n",
    "                if token.ent_iob_ == \"B\":\n",
    "                    pred_tags.append(f\"B-{token.ent_type_}\")\n",
    "                else:\n",
    "                    pred_tags.append(f\"I-{token.ent_type_}\")\n",
    "            else:\n",
    "                pred_tags.append(\"O\")\n",
    "\n",
    "        # Ground truth\n",
    "        true_tags = [\"O\"] * len(doc)\n",
    "        for start, end, label in annotations[\"entities\"]:\n",
    "            for token_idx, token in enumerate(doc):\n",
    "                if start <= token.idx < end:\n",
    "                    if token.idx == start or (token_idx > 0 and doc[token_idx - 1].idx < start):\n",
    "                        true_tags[token_idx] = f\"B-{label}\"\n",
    "                    else:\n",
    "                        true_tags[token_idx] = f\"I-{label}\"\n",
    "\n",
    "        pred_entities_list.append(pred_tags)\n",
    "        true_entities_list.append(true_tags)\n",
    "\n",
    "    report = classification_report(true_entities_list, pred_entities_list, scheme=IOB2, output_dict=True)\n",
    "    f1 = f1_score(true_entities_list, pred_entities_list, scheme=IOB2)\n",
    "    return report, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c7be34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasi 1/100\n",
      "Losses: {'ner': 10773.590295147227}\n",
      "\n",
      "Iterasi 2/100\n",
      "Losses: {'ner': 1753.7035875022386}\n",
      "\n",
      "Iterasi 3/100\n",
      "Losses: {'ner': 1519.4452119455345}\n",
      "\n",
      "Iterasi 4/100\n",
      "Losses: {'ner': 1419.1594352971583}\n",
      "\n",
      "Iterasi 5/100\n",
      "Losses: {'ner': 1188.8073368972784}\n",
      "\n",
      "Iterasi 6/100\n",
      "Losses: {'ner': 1144.0515705734822}\n",
      "\n",
      "Iterasi 7/100\n",
      "Losses: {'ner': 1011.1055907290774}\n",
      "\n",
      "Iterasi 8/100\n",
      "Losses: {'ner': 897.9154077345764}\n",
      "\n",
      "Iterasi 9/100\n",
      "Losses: {'ner': 854.6104767243393}\n",
      "\n",
      "Iterasi 10/100\n",
      "Losses: {'ner': 791.3761571799857}\n",
      "[Span Matching] Precision: 0.52, Recall: 0.40, F1: 0.45\n",
      "[BIO Tagging] F1: 0.45\n",
      "Detail Classification Report:\n",
      "APP: precision=0.62, recall=0.50, f1-score=0.55\n",
      "DESC: precision=0.24, recall=0.17, f1-score=0.20\n",
      "Model disimpan pada iterasi 10 dengan F1 BIO: 0.45\n",
      "\n",
      "\n",
      "Iterasi 11/100\n",
      "Losses: {'ner': 858.5273676703397}\n",
      "\n",
      "Iterasi 12/100\n",
      "Losses: {'ner': 697.1362087055364}\n",
      "\n",
      "Iterasi 13/100\n",
      "Losses: {'ner': 666.6477624059769}\n",
      "\n",
      "Iterasi 14/100\n",
      "Losses: {'ner': 613.0548585387511}\n",
      "\n",
      "Iterasi 15/100\n",
      "Losses: {'ner': 579.8305523501011}\n",
      "\n",
      "Iterasi 16/100\n",
      "Losses: {'ner': 593.939048420907}\n",
      "\n",
      "Iterasi 17/100\n",
      "Losses: {'ner': 559.1366534964692}\n",
      "\n",
      "Iterasi 18/100\n",
      "Losses: {'ner': 485.07095292137683}\n",
      "\n",
      "Iterasi 19/100\n",
      "Losses: {'ner': 463.6808897199131}\n",
      "\n",
      "Iterasi 20/100\n",
      "Losses: {'ner': 465.5064528593615}\n",
      "[Span Matching] Precision: 0.51, Recall: 0.45, F1: 0.47\n",
      "[BIO Tagging] F1: 0.47\n",
      "Detail Classification Report:\n",
      "APP: precision=0.60, recall=0.55, f1-score=0.58\n",
      "DESC: precision=0.24, recall=0.19, f1-score=0.21\n",
      "Model disimpan pada iterasi 20 dengan F1 BIO: 0.47\n",
      "\n",
      "\n",
      "Iterasi 21/100\n",
      "Losses: {'ner': 404.415323550548}\n",
      "\n",
      "Iterasi 22/100\n",
      "Losses: {'ner': 375.4490505914472}\n",
      "\n",
      "Iterasi 23/100\n",
      "Losses: {'ner': 380.2665569459583}\n",
      "\n",
      "Iterasi 24/100\n",
      "Losses: {'ner': 377.37251315181993}\n",
      "\n",
      "Iterasi 25/100\n",
      "Losses: {'ner': 321.7351052890965}\n",
      "\n",
      "Iterasi 26/100\n",
      "Losses: {'ner': 337.2869939752926}\n",
      "\n",
      "Iterasi 27/100\n",
      "Losses: {'ner': 306.32171250183535}\n",
      "\n",
      "Iterasi 28/100\n",
      "Losses: {'ner': 321.10838209071983}\n",
      "\n",
      "Iterasi 29/100\n",
      "Losses: {'ner': 251.7895394381199}\n",
      "\n",
      "Iterasi 30/100\n",
      "Losses: {'ner': 283.8125067442808}\n",
      "[Span Matching] Precision: 0.46, Recall: 0.46, F1: 0.46\n",
      "[BIO Tagging] F1: 0.46\n",
      "Detail Classification Report:\n",
      "APP: precision=0.57, recall=0.55, f1-score=0.56\n",
      "DESC: precision=0.22, recall=0.24, f1-score=0.23\n",
      "\n",
      "\n",
      "Iterasi 31/100\n",
      "Losses: {'ner': 260.44985451858867}\n",
      "\n",
      "Iterasi 32/100\n",
      "Losses: {'ner': 248.56957473093703}\n",
      "\n",
      "Iterasi 33/100\n",
      "Losses: {'ner': 252.46460888470997}\n",
      "\n",
      "Iterasi 34/100\n",
      "Losses: {'ner': 259.7863297559398}\n",
      "\n",
      "Iterasi 35/100\n",
      "Losses: {'ner': 235.6625714090195}\n",
      "\n",
      "Iterasi 36/100\n",
      "Losses: {'ner': 245.3618383510623}\n",
      "\n",
      "Iterasi 37/100\n",
      "Losses: {'ner': 220.18487996299677}\n",
      "\n",
      "Iterasi 38/100\n",
      "Losses: {'ner': 246.2663318229309}\n",
      "\n",
      "Iterasi 39/100\n",
      "Losses: {'ner': 225.8064536208738}\n",
      "\n",
      "Iterasi 40/100\n",
      "Losses: {'ner': 225.36354428345504}\n",
      "[Span Matching] Precision: 0.52, Recall: 0.44, F1: 0.48\n",
      "[BIO Tagging] F1: 0.48\n",
      "Detail Classification Report:\n",
      "APP: precision=0.60, recall=0.53, f1-score=0.57\n",
      "DESC: precision=0.28, recall=0.20, f1-score=0.23\n",
      "Model disimpan pada iterasi 40 dengan F1 BIO: 0.48\n",
      "\n",
      "\n",
      "Iterasi 41/100\n",
      "Losses: {'ner': 207.36156498514583}\n",
      "\n",
      "Iterasi 42/100\n",
      "Losses: {'ner': 213.2735453315718}\n",
      "\n",
      "Iterasi 43/100\n",
      "Losses: {'ner': 199.35965852622084}\n",
      "\n",
      "Iterasi 44/100\n",
      "Losses: {'ner': 179.52221486301985}\n",
      "\n",
      "Iterasi 45/100\n",
      "Losses: {'ner': 172.5278615571179}\n",
      "\n",
      "Iterasi 46/100\n",
      "Losses: {'ner': 193.09431005159902}\n",
      "\n",
      "Iterasi 47/100\n",
      "Losses: {'ner': 193.65342035516463}\n",
      "\n",
      "Iterasi 48/100\n",
      "Losses: {'ner': 178.66059305683794}\n",
      "\n",
      "Iterasi 49/100\n",
      "Losses: {'ner': 164.42496263018592}\n",
      "\n",
      "Iterasi 50/100\n",
      "Losses: {'ner': 184.2221265417941}\n",
      "[Span Matching] Precision: 0.51, Recall: 0.39, F1: 0.44\n",
      "[BIO Tagging] F1: 0.44\n",
      "Detail Classification Report:\n",
      "APP: precision=0.59, recall=0.47, f1-score=0.52\n",
      "DESC: precision=0.29, recall=0.22, f1-score=0.25\n",
      "\n",
      "\n",
      "Iterasi 51/100\n",
      "Losses: {'ner': 147.3513244286603}\n",
      "\n",
      "Iterasi 52/100\n",
      "Losses: {'ner': 169.62207684334953}\n",
      "\n",
      "Iterasi 53/100\n",
      "Losses: {'ner': 155.34645085444427}\n",
      "\n",
      "Iterasi 54/100\n",
      "Losses: {'ner': 182.22606503604993}\n",
      "\n",
      "Iterasi 55/100\n",
      "Losses: {'ner': 148.01550099258688}\n",
      "\n",
      "Iterasi 56/100\n",
      "Losses: {'ner': 203.49613236256775}\n",
      "\n",
      "Iterasi 57/100\n",
      "Losses: {'ner': 151.96873126828382}\n",
      "\n",
      "Iterasi 58/100\n",
      "Losses: {'ner': 147.920769741685}\n",
      "\n",
      "Iterasi 59/100\n",
      "Losses: {'ner': 146.03129492626988}\n",
      "\n",
      "Iterasi 60/100\n",
      "Losses: {'ner': 138.97935514418924}\n",
      "[Span Matching] Precision: 0.52, Recall: 0.43, F1: 0.47\n",
      "[BIO Tagging] F1: 0.47\n",
      "Detail Classification Report:\n",
      "APP: precision=0.59, recall=0.52, f1-score=0.55\n",
      "DESC: precision=0.30, recall=0.20, f1-score=0.24\n",
      "\n",
      "\n",
      "Iterasi 61/100\n",
      "Losses: {'ner': 145.5561000673258}\n",
      "\n",
      "Iterasi 62/100\n",
      "Losses: {'ner': 135.03156069606274}\n",
      "\n",
      "Iterasi 63/100\n",
      "Losses: {'ner': 138.97775803543226}\n",
      "\n",
      "Iterasi 64/100\n",
      "Losses: {'ner': 137.21775809418236}\n",
      "\n",
      "Iterasi 65/100\n",
      "Losses: {'ner': 117.95800475622133}\n",
      "\n",
      "Iterasi 66/100\n",
      "Losses: {'ner': 141.49174824423633}\n",
      "\n",
      "Iterasi 67/100\n",
      "Losses: {'ner': 158.4752509574146}\n",
      "\n",
      "Iterasi 68/100\n",
      "Losses: {'ner': 111.81357349281622}\n",
      "\n",
      "Iterasi 69/100\n",
      "Losses: {'ner': 145.99419575265122}\n",
      "\n",
      "Iterasi 70/100\n",
      "Losses: {'ner': 108.6642413983376}\n",
      "[Span Matching] Precision: 0.49, Recall: 0.45, F1: 0.47\n",
      "[BIO Tagging] F1: 0.47\n",
      "Detail Classification Report:\n",
      "APP: precision=0.58, recall=0.54, f1-score=0.56\n",
      "DESC: precision=0.25, recall=0.22, f1-score=0.23\n",
      "\n",
      "\n",
      "Iterasi 71/100\n",
      "Losses: {'ner': 130.2734779599956}\n",
      "\n",
      "Iterasi 72/100\n",
      "Losses: {'ner': 106.84548519414803}\n",
      "\n",
      "Iterasi 73/100\n",
      "Losses: {'ner': 112.93432938092604}\n",
      "\n",
      "Iterasi 74/100\n",
      "Losses: {'ner': 125.55962687658183}\n",
      "\n",
      "Iterasi 75/100\n",
      "Losses: {'ner': 116.7792652104169}\n",
      "\n",
      "Iterasi 76/100\n",
      "Losses: {'ner': 133.45278621548954}\n",
      "\n",
      "Iterasi 77/100\n",
      "Losses: {'ner': 100.54502700836754}\n",
      "\n",
      "Iterasi 78/100\n",
      "Losses: {'ner': 92.26314726313704}\n",
      "\n",
      "Iterasi 79/100\n",
      "Losses: {'ner': 82.21811932606886}\n",
      "\n",
      "Iterasi 80/100\n",
      "Losses: {'ner': 94.40059610635267}\n",
      "[Span Matching] Precision: 0.51, Recall: 0.41, F1: 0.45\n",
      "[BIO Tagging] F1: 0.45\n",
      "Detail Classification Report:\n",
      "APP: precision=0.62, recall=0.49, f1-score=0.55\n",
      "DESC: precision=0.25, recall=0.20, f1-score=0.22\n",
      "\n",
      "\n",
      "Iterasi 81/100\n",
      "Losses: {'ner': 98.00659048301021}\n",
      "\n",
      "Iterasi 82/100\n",
      "Losses: {'ner': 124.56446939471545}\n",
      "\n",
      "Iterasi 83/100\n",
      "Losses: {'ner': 103.80417252554278}\n",
      "\n",
      "Iterasi 84/100\n",
      "Losses: {'ner': 88.00601043686267}\n",
      "\n",
      "Iterasi 85/100\n",
      "Losses: {'ner': 95.94601721127967}\n",
      "\n",
      "Iterasi 86/100\n",
      "Losses: {'ner': 130.61127492542946}\n",
      "\n",
      "Iterasi 87/100\n",
      "Losses: {'ner': 99.53289161306223}\n",
      "\n",
      "Iterasi 88/100\n",
      "Losses: {'ner': 110.47582847898764}\n",
      "\n",
      "Iterasi 89/100\n",
      "Losses: {'ner': 123.89040365830891}\n",
      "\n",
      "Iterasi 90/100\n",
      "Losses: {'ner': 68.51636857904369}\n",
      "[Span Matching] Precision: 0.49, Recall: 0.46, F1: 0.47\n",
      "[BIO Tagging] F1: 0.47\n",
      "Detail Classification Report:\n",
      "APP: precision=0.56, recall=0.55, f1-score=0.56\n",
      "DESC: precision=0.27, recall=0.22, f1-score=0.24\n",
      "\n",
      "\n",
      "Iterasi 91/100\n",
      "Losses: {'ner': 105.01289891560424}\n",
      "\n",
      "Iterasi 92/100\n",
      "Losses: {'ner': 112.27692849890461}\n",
      "\n",
      "Iterasi 93/100\n",
      "Losses: {'ner': 83.00749808832624}\n",
      "\n",
      "Iterasi 94/100\n",
      "Losses: {'ner': 111.40657128931495}\n",
      "\n",
      "Iterasi 95/100\n",
      "Losses: {'ner': 89.05331906175456}\n",
      "\n",
      "Iterasi 96/100\n",
      "Losses: {'ner': 87.99452148023659}\n",
      "\n",
      "Iterasi 97/100\n",
      "Losses: {'ner': 80.09806410070237}\n",
      "\n",
      "Iterasi 98/100\n",
      "Losses: {'ner': 85.69891510545918}\n",
      "\n",
      "Iterasi 99/100\n",
      "Losses: {'ner': 91.29548624666349}\n",
      "\n",
      "Iterasi 100/100\n",
      "Losses: {'ner': 85.34286798972747}\n",
      "[Span Matching] Precision: 0.49, Recall: 0.40, F1: 0.44\n",
      "[BIO Tagging] F1: 0.44\n",
      "Detail Classification Report:\n",
      "APP: precision=0.61, recall=0.47, f1-score=0.53\n",
      "DESC: precision=0.25, recall=0.22, f1-score=0.24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Loop Training\n",
    "for itn in range(n_iter):\n",
    "    print(f\"Iterasi {itn + 1}/{n_iter}\")\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Mini-batch\n",
    "    batches = [TRAIN_DATA[i:i+4] for i in range(0, len(TRAIN_DATA), 4)]\n",
    "    for batch in batches:\n",
    "        examples = []\n",
    "        for text, annotations in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            examples.append(example)\n",
    "        nlp.update(examples, drop=0.2, losses=losses)\n",
    "\n",
    "    # Evaluasi setiap 10 iterasi\n",
    "    if (itn + 1) % 10 == 0:\n",
    "        print(f\"Losses: {losses}\")\n",
    "\n",
    "        # Evaluasi 1: Span Matching\n",
    "        p1, r1, f1_span = evaluate_span(nlp, VALID_DATA)\n",
    "        print(f\"[Span Matching] Precision: {p1:.2f}, Recall: {r1:.2f}, F1: {f1_span:.2f}\")\n",
    "\n",
    "        # Evaluasi 2: Tagging BIO\n",
    "        report, f1_tagging = evaluate_bio(nlp, VALID_DATA)\n",
    "        print(f\"[BIO Tagging] F1: {f1_tagging:.2f}\")\n",
    "        print(\"Detail Classification Report:\")\n",
    "        for label, scores in report.items():\n",
    "            if label not in [\"micro avg\", \"macro avg\", \"weighted avg\"]:\n",
    "                print(f\"{label}: precision={scores['precision']:.2f}, recall={scores['recall']:.2f}, f1-score={scores['f1-score']:.2f}\")\n",
    "\n",
    "        # Simpan jika F1 tagging terbaik\n",
    "        if f1_tagging > best_f1_tagging:\n",
    "            best_f1_tagging = f1_tagging\n",
    "            model_dir = f\"./models5/model_iter{itn+1}\"\n",
    "            os.makedirs(\"./models5\", exist_ok=True)\n",
    "            nlp.to_disk(model_dir)\n",
    "            print(f\"Model disimpan pada iterasi {itn+1} dengan F1 BIO: {f1_tagging:.2f}\")\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Losses: {losses}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f070fac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pelatihan selesai. Model final disimpan.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./models5\"):\n",
    "    os.makedirs(\"./models5\")\n",
    "nlp.to_disk(\"./models5/model_final\")\n",
    "print(\"Pelatihan selesai. Model final disimpan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
